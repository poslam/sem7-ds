1. Типы данных. Понятие однородности / неоднородности. Двойственность формулировки

	- однородность (звук, текст, изображение)
		* одинаковая природа
		* нет пространственных зависимостей
	- неоднородность - разная природа и тип данных

	**Двойственность формулировки однородности** через два варианта определения:
	- данные однородны, если они имеют одинаковую природу (сигнал, изображение)
	- данные однородны, если нет пространственных связей (первая строка не связана ни с какой другой)

	**Исходные данные – неоднородны, но после обработки – однородны**, потому что любая модель требует работы в едином числовом пространстве признаков.

2. Типы данных. Категориальные / количественные. Методы предобработки. Отличия

	Типы данных:
	1. количественные (обычно непрерывные)
		- непрерывные 
		- дискретные
	2. качественные 
		- порядковые (ещё сравнить можно, по какой-то договорённости)
		- номинальные (не работают операторы сравнения)

	методы преобработки категориальных признаков:
	- Label Encoder (**присваивает каждой категории в рамках столбца свой индекс; плохо для лин. регресси, тк 0<1, хотя это две категории**)
	- One-Hot Encoder (**_Главный недостаток One-Hot Encoder'a заключается в существенном увеличении объема данных, так как большие по количеству уникальных значений признаки кодируются большим количеством бинарных признаков._**)
	- Binary Encoder - представление в двоичном виде()
		![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/bf9/bd1/15e/bf9bd115e33d0d165448c854de4688f4.png)
	
	методы предобработки количественных признаков:
	- scaler
	- устранение пропущенных значений
	- работа с выбросами (IQR, Z-score)
	
	отличия:

| Критерий                               | Категориальные Данные                           | Количественные Данные                              |
| -------------------------------------- | ----------------------------------------------- | -------------------------------------------------- |
| **Суть**                               | Описывают **качество**, принадлежность к группе | Описывают **количество**, измеряемую величину      |
| **Математические операции**            | Не имеют смысла (нельзя найти "средний" цвет)   | Имеют смысл (можно найти средний возраст)          |
| **Примеры**                            | Пол, страна, бренд                              | Возраст, цена, рост                                |
| **Основные методы  <br>предобработки** | One-Hot Encoding, Label Encoding                | Масштабирование (Нормализация, Стандартизация)     |
| **Типы визуализации**                  | Столбчатые диаграммы, круговые диаграммы        | Гистограммы, ящики с усами (boxplot), scatter plot |
| **Меры центральной тенденции**         | Мода (самая частая категория)                   | Среднее значение, медиана                          |

3. Типы задач решаемых ИИ. Обучение с учителем / без учителя / с подкреплением. Формальная постановка задач

	- обучение с учителем:
		- регрессия
		- классификация
		- ранжирование
	- обучение без учителя:
		- кластеризация
		- понижение размерности
		- поиск аномалий
		- генерация
	- частичный контроль (как вариант - искусственный таргет)
	- обучение с подкреплением - максимизация награды

	постаноки:
	- задачи c учителем:
		- пусть $D = \{ (\overline x_{i}, y_{i}) \}, x_{i} \in X, y_{i} \in Y$
		- пусть $L: (Y,Y) \to R$ - функция ошибки
		- Модель: $M(\xi, X) \to \hat{Y}$, где $\xi$ - вектор параметров
		- задача: $L(Y,M(\xi^{*}, X)) = L(Y, \hat{ Y}) \to\min$

	- задачи без учителя:
		- пусть $X = \{ x_{i} \}$
		- Пусть $L:(x_{1},x_{2}, \dots, x_{n}) \to R$
		- $M(\xi, X) \to (x_{1},x_{2},\dots,x_{n})$
		(тут под каждую задачу отдельная формализация)

4. Постановка регрессии как задачи оптимизации. Метрики и функции ошибки задачи регрессии, Отличия, Понятия интерпретируемости. Случаи использования

	**Формальная постановка:**

	- Дано: **Выборка данных** `D = {(x₁, y₁), (x₂, y₂), ..., (xₘ, yₘ)}`, где `xᵢ ∈ Rⁿ` — вектор признаков i-го объекта, а `yᵢ ∈ R` — его настоящее (истинное) значение целевой переменной.
	    
	- Модель: Мы предполагаем, что существует некая функция `f(x, θ)`, которая приближает зависимость `y` от `x`. Здесь `θ` — параметры модели (например, веса в линейной регрессии `θ = (w, b)`, где `y ≈ wᵀx + b`).
	    
	- Функция потерь (Loss Function): `L(f(x, θ), y)` — функция, которая измеряет, насколько предсказание `f(x, θ)` отличается от истинного значения `y`. Это "штраф" за ошибку.
	 Основные функции ошибок и метрики:
	
	**1. MSE (Mean Squared Error) / Среднеквадратичная ошибка (L2-loss)**  
	* **Формула:** `MSE = (1/m) * Σ(yᵢ - ŷᵢ)²`  
	* **Свойства:**  
	* **Отличие:** Сильно штрафует за большие ошибки (из-за квадрата). Чувствительна к выбросам.  
	* **Производная:** `2*(ŷᵢ - yᵢ)` — градиент растет с ростом ошибки, что помогает быстро исправлять крупные промахи.  
	* **Когда использовать:** Когда выбросы в данных являются важными и их нужно сильно "наказывать". Стандартный выбор для многих задач.
	
	**2. MAE (Mean Absolute Error) / Средняя абсолютная ошибка (L1-loss)**  
	* **Формула:** `MAE = (1/m) * Σ|yᵢ - ŷᵢ|`  
	* **Свойства:**  
	* **Отличие:** Штрафует линейно, менее чувствительна к выбросам, чем MSE.  
	* **Производная:** `sign(ŷᵢ - yᵢ)` — градиент постоянный, что может замедлить сходимость на малых ошибках.  
	* **Когда использовать:** Когда в данных много выбросов, и вы хотите, чтобы модель была к ним устойчива.
	
	**3. RMSE (Root Mean Squared Error) / Cреднеквадратичное отклонение**  
	* **Формула:** `RMSE = √MSE`  
	* **Свойства:**  
	* **Отличие:** Имеет ту же размерность, что и предсказываемая величина `y`. Это делает метрику более интерпретируемой. Сохраняет чувствительность к выбросам.  
	* **Когда использовать:** Почти всегда как основная метрика для отчетности, потому что она в "понятных" единицах (рубли, метры, часы).
	
	**4. MAPE (Mean Absolute Percentage Error) / Средняя абсолютная ошибка в процентах**  
	* **Формула:** `MAPE = (1/m) * Σ |(yᵢ - ŷᵢ)/yᵢ| * 100%`  
	* **Свойства:**  
	* **Отличие:** Относительная метрика, не зависит от масштаба данных. Полезна для сравнения моделей на разных наборах данных.  
	* **Минусы:** Не определена, если `yᵢ = 0`. Может давать огромные ошибки, если истинные значения `y` близки к нулю.  
	* **Когда использовать:** В задачах прогнозирования спроса, продаж, где важны относительные ошибки.
	
	**Задача оптимизации:** Найти такие параметры модели `θ*`, которые минимизируют **средний штраф** (эмпирический риск) на всей обучающей выборке:
	
	`θ* = argmin_θ (1/m) * Σᵢ₌₁ᵐ L(f(xᵢ, θ), yᵢ)`
	
	На практике часто минимизируют просто сумму потерь, так как константа `1/m` не влияет на точку минимума:
	
	`θ* = argmin_θ Σᵢ₌₁ᵐ L(f(xᵢ, θ), yᵢ)`

	**R² (Coefficient of Determination) / Коэффициент детерминации**  
	* **Формула:** `R² = 1 - (Σ(yᵢ - ŷᵢ)²) / (Σ(yᵢ - ȳ)²)`  
	* **Свойства:**  
	* **Отличие:** Показывает, какую долю дисперсии целевой переменной объясняет наша модель. Идеальная модель имеет `R² = 1`. Модель, всегда предсказывающая среднее, имеет `R² = 0`. Может быть отрицательной, если модель предсказывает хуже, чем просто среднее значение.  
	* **Когда использовать:** Как основная интерпретируемая метрика для сравнения моделей на одном и том же наборе данных.

5. Вывод аналитического решения задачи линейной регрессии в векторной форме (ps при дифф. первое слагаемое можно сжато)

	$$y = Xw + \varepsilon$$
	$$L(w) = \|y - Xw\|^{2}= (y - Xw)^\top (y - Xw)$$
	$$L(w)= y^\top y - y^\top Xw - w^\top X^\top y + w^\top X^\top X w$$
	$$L(w)= y^\top y - 2 w^\top X^\top y + w^\top X^\top X w$$

	Используем стандартные правила дифференцирования квадратичных форм:
	- $\nabla_w (w^\top A w) = (A + A^\top) w$
	- если A симметрична → $(A+A^T)=2A$,
	- $\nabla_w (b^\top w) = b$.

	$$\nabla L = -2X^{T}y + 2X^TXw = 0$$
	$$w = (X^TX)^{-1}X^Ty$$

6. Постановка регрессии как задачи оптимизации. Модели применяемые для решения задачи. Внесение нелинейности в линейные модели. Случаи использования

	Хотим найти параметры $\omega$, которые минимизируют среднеквадратичную ошибку (MSE): $\min_{w} \; L(w) = \|y - Xw\|^2$.
	## **Линейные модели**
		- аналитическое решение
		- методы регуляризации

	Для устойчивости и борьбы с переобучением:
	- **Ridge-регрессия (L2):**    
	    $L(w)=\|y-Xw\|^2+\lambda\|w\|^2$
	- **Lasso-регрессия (L1):**
	    $L(w)=\|y-Xw\|^2+\lambda\|w\|_1$​.
	- **Elastic Net:** смесь L1 и L2.
	Формально остаются линейными по параметрам, но вводят нелинейность по входу:
		- Полиномиальные признаки
		- RBF (гауссовы) признаки
		- Сплайны
		- Произвольные ручные преобразования

	Модель остаётся линейной: $\hat y = \Phi(X) w$, но не обязательно линейной по исходным переменным.

	## **Нелинейные модели**

	Если линейность в любом виде неэффективна:
	- Деревья решений
	- Случайный лес
	- Градиентный бустинг (XGBoost, CatBoost, LightGBM)
	- Нейронные сети
	- SVR (SVM для регрессии с kernel trick)

7. Метрики задачи классификации (бинарной и мультиклассификации). ROC AUC. Вычисление AUC. Подбор гиперпараметра классификации. Примеры выбора метрик для задачи бинарной классификации.

|     | п+  | п-  |
| --- | --- | --- |
| ф+  | tp  | fn  |
| ф-  | fp  | tn  |

Базовые метрики:
- **Accuracy (Точность)**: `(TP + TN) / (TP + TN + FP + FN)`
- **Precision (Точность предсказания)**: `TP / (TP + FP)`
- **Recall (Полнота)**: `TP / (TP + FN)`
- **F1-score**: `2 * (Precision * Recall) / (Precision + Recall)`
- **ROC AUC** (Receiver Operating Characteristic - Area Under Curve)
	
	ROC-кривая строится путем варьирования порога классификации и вычисления:
	- **TPR (True Positive Rate) = Recall = TP / (TP + FN)**
	- **FPR (False Positive Rate) = FP / (FP + TN)**

	Алгоритм состоит из:
	1. сортировки по score,
	2. перебора порогов,
	3. вычисления (FPR, TPR),
	4. построения кривой,
	5. интегрирования площади (AUC).

	Вероятностная интерпретация ROC AUC - AUC равен вероятности, что случайно выбранный позитив имеет score выше, чем случайно выбранный негатив
	$$AUC = \sum_{i=1}^{n-1} (FPR_{i+1} - FPR_i) \cdot \frac{TPR_{i+1} + TPR_i}{2}$$

	выбирает стратегию поиска (grid, random, bayesian, hyperband и т.п.);
	метрики
	$\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad l_n = - w_n \left[ y_n \cdot \log x_n + (1 - y_n) \cdot \log (1 - x_n) \right]$
	
8. Метрики задачи классификации (бинарной и мультиклассификации). Модернизация метрик для задачи мультиклассификации. Примеры выбора метрик для задачи мультиклассификации.

	метрики меняются или на OvO, или на OvRest
	![](https://wikimedia.org/api/rest_v1/media/math/render/svg/ee9b2235daf4402960538e73d6310bc8c2b8de52)

	Для деревьев и леса: лучше случайно выбирать признаки на каждом уровне, а не пулл на дерево 

9. Алгоритм построения дерева решений для задачи классификации(регрессии). Критерии останова + критерии разбиения (при задаче регрессии / классификации

	Это рекурсивный алгоритм "разделяй и властвуй", который на каждом шаге выбирает **локально наилучшее** разбиение.

	**Начало:** Всё множество данных (все наблюдения) помещается в **корневой узел**.
    
	**Выбор лучшего разбиения:** Для каждого признака в текущем узле вычисляется, насколько "хорошим" будет разбиение данных по этому признаку. "Хорошесть" измеряется критерием (о них ниже).
    
    - Для **категориальных признаков** разбиение проверяется по всем возможным подмножествам категорий (или просто по каждой категории).
    - Для **непрерывных признаков** данные сначала сортируются по значению признака, а затем проверяются все возможные пороги разбиения (например, середина между двумя соседними значениями).
		- **Создание дочерних узлов:** Выбирается признак и порог/значение, которые дают **наилучшее** (максимальное) значение выбранного критерия. Данные в текущем узле разделяются на 2 (или более) подмножества согласно выбранному правилу. Для каждого подмножества создается новый дочерний узел.
		- **Рекурсия:** Шаги 2 и 3 рекурсивно повторяются для каждого нового дочернего узла, пока не будет выполнено хотя бы одно из **условий останова**.
		- **Создание листа (терминального узла):** Когда рекурсия останавливается, текущий узел объявляется **листом**. В листе записывается итоговое значение:
    - Для **классификации:** тот класс, который наиболее часто встречается в наблюдениях, попавших в этот узел (мода, majority class).
    - Для **регрессии:** среднее значение целевой переменной по наблюдениям, попавшим в этот узел.

10. Алгоритм построения дерева решений для задачи классификации(регрессии). Критерии разбиения (при задаче регрессии / классификации) + обработка категориальных признаков при построении деревьев
	см выше

11. Постановка задачи кластеризации. Метод K-means. Алгоритм нахождения кластеров. Улучшения по сходимости / времени. Метрики кластеризации

	- кластеризация:
	Дано $X = \{ x_{1}, x_{2}, \dots, x_{n} \}, x_{i} \in \mathbb{R}^{d}$, d- размерность признаков. надо разбить $X$ на группы $C_{i}$: $C = \{ C_{1}, C_{2}, \dots,C_{n} \}, C_{i} \subseteq X$. Объекты внутри кластера схожи по введённой метрике на пространстве признаков.
		- K-means:
			1. задаём количество кластеров (можно через метод локтя и метрику ошибки)
			2. выбираем случайные центроиды (почти случайные, надо брать на расстоянии) ((можно из X, но не всегда))
			3. считаем расстояния до центроид.
			4. если алгоритм глупенький, то положим, что центроида на минимальном расстоянием является центром кластера, к которому теперь принадлежит $x_{i}$.
			5. теперь надо сместить центроиды (различные подходы) ((как вариант, можно переместить в центр кластера (на кругах не сработает)))
		- **Алгоритм Элкана (Elkan's K-means):** Использует неравенство треугольника для избежания избыточных вычислений расстояний. Если известны расстояния между центроидами, можно сделать вывод, что точка не может быть ближе к одному центроиду, чем к другому, без явного вычисления. Значительно ускоряет работу, особенно когда `k` велико.
		- **Mini-Batch K-means:** На каждой итерации вместо всего датасета используется небольшая случайная подвыборка (mini-batch). Центроиды обновляются на основе этой подвыборки. Это грубая, но гораздо более быстрая аппроксимация, хорошо работающая на больших данных.
	- метрики:
		- **Inertia (Within-Cluster Sum of Squares, WCSS):** 

			Сумма квадратов расстояний от точек до центроида их кластера. Это тот самый функционал `J`, который минимизирует K-means.

	    	- **Плюсы:** Простота.
	    	- **Минусы:** Не имеет верхней границы, монотонно уменьшается с ростом `k`, поэтому непригодна для выбора `k` без дополнений (см. метод локтя).

		- **Silhouette Score (Силуэт):** 
	
			Для каждой точки вычисляется, насколько она похожа на свой кластер (среднее расстояние до точек в своем кластере, `a`) по сравнению с другими кластерами (среднее расстояние до точек в ближайшем соседнем кластере, `b`).

			- **Коэффициент силуэта**:
				- $a_i$ - среднее расстояние от однойточки до всех точек своего кластера	
				- $b_i$ - минимальное среднее расстояние от точки одного кластера до точек другого кластера

			$$s_i = \frac{b_i - a_i}{\max(a_i, b_i)}, \ score = \frac{1}{N} \sum s_i$$
				
			Интерпретация: чем ближе к 1, тем более компактные и далёкие друг от друга кластеры.(-1, 1)

			- Значения от -1 до 1. Чем ближе к 1, тем лучше (точка четко отнесена к своему кластеру).
			- Усредненный по всем точкам силуэт дает общую оценку кластеризации.

		- **Calinski-Harabasz Index (Variance Ratio Criterion):** Отношение дисперсии между кластерами к дисперсии внутри кластеров. Чем выше показатель, тем лучше разделены кластеры.

			- $\mu$ - глобальный центр всех данных, 
			- $\mu_k$ - центр кго кластера,
			- $n_k$ - размер кластера,
			- $K$ - число кластеров,
			- $N$ - Число точек,

			Начинается жесть: 
			- матожидание межкластерного разброса: $B=\sum n_k ||\mu_k - \mu||^2$
			- матожидание внутрикластерного разброса: $W = \sum_{k, x_i} ||x_i - \mu_k||^2$
			- score $CH = \frac{B/(K-1)}{W/(N-k)}$
			
			чем больше, тем лучше.

		- **Davies-Bouldin Index:** 
		
			Усредненное отношение "размеров" кластеров к расстоянию между ними. Чем **меньше** показатель, тем лучше разделены кластеры.

			$S_k$ - среднее внутрекластерное расстояние $$ S_k = \frac{1}{|C|} \sum_{x_i \in C_k} ||x_i - \mu_k||$$
			
			$M_{jk}$ - расстояние между двумя центрами двух кластеров.$$M_{k,j} = ||\mu_k - \mu_j||$$
				
			для пары кластеров $$R_{kj} = \frac{S_k + S_j}{M_{kj}}$$
			для каждого кластера выбираем худжего соседа: $$R_k = max_{i\ne k} R_{kj}$$
			Итоговый индекс: $$DB = \frac{1}{K}\sum R_k$$
			Интерпретация: меньше — лучше.

12. Постановка задачи кластеризации. Иерархические и аггломеративные методы кластеризации. Их преимущества. Метрики кластеризации.

	Идея: строится **дерево кластеров (дендрограмма)**, показывающее, как объекты объединяются в группы на разных уровнях детализации.	

	**Виды:**
	- **Аггломеративная (bottom-up)** – начинаем с каждого объекта как отдельного кластера и постепенно объединяем ближайшие кластеры.
	- **Дивизивная (top-down)** – начинаем с одного кластера, включающего все объекты, и постепенно делим его на подгруппы.

	**Этапы аггломеративной кластеризации:**
	1. Каждый объект – отдельный кластер.
	2. Вычисляем расстояния между всеми кластерами (например, евклидово, манхэттенское, косинусное).
	3. Объединяем два ближайших кластера.
	4. Обновляем матрицу расстояний.
	5. Повторяем, пока не останется один кластер или не достигнем заданного числа кластеров.

	**Методы измерения расстояния между кластерами:**
	- **Single linkage** – минимальное расстояние между объектами двух кластеров.
	- **Complete linkage** – максимальное расстояние.
	- **Average linkage** – среднее расстояние между всеми объектами.
	- **Ward’s method** – минимизация внутрикластерной дисперсии при объединении.

	**Преимущества иерархической и аггломеративной кластеризации**
	1. **Не требуется заранее задавать число кластеров** (особенно удобно при исследовательском анализе данных).
	2. **Дендрограмма визуализирует структуру данных**, позволяя увидеть, как объекты и кластеры связаны между собой.
	3. **Гибкость** – можно выбрать разные меры расстояния и методы объединения для адаптации к данным.
	4. **Интерпретируемость** – легко объяснить, почему объекты попали в один кластер.
	5. **Подходит для небольших и средних наборов данных** с высокой структурной информацией.

13. Постановка задачи кластеризации. DBSCAN. Метрики кластеризации.
	
	DBSCAN — это алгоритм кластеризации, основанный на плотности. Он выделяет кластеры как области высокой плотности объектов, отделяя их от областей низкой плотности (шум).

	### **Основные идеи и параметры**
	1. **Параметры:**
	    - **ε (epsilon)** – радиус окрестности для поиска соседей.
	    - **MinPts** – минимальное число точек в окрестности, чтобы считать точку «ядром» кластера.
	2. **Типы точек:**
	    - **Ядро (core point)** – точка, у которой в радиусе ε есть ≥ MinPts точек.
	    - **Пограничная (border point)** – точка в радиусе ядра, но сама не является ядром.
	    - **Шум (noise point)** – точка, не относящаяся ни к одному кластеру.
	3. **Принцип работы:**
	    1. Выбираем случайную не посещённую точку.
	    2. Если это ядро → создаём новый кластер, добавляем все точки в его ε-окрестности.
	    3. Расширяем кластер рекурсивно через ядра соседей.
	    4. Если точка не ядро → помечаем как шум (может позже стать пограничной).
	    5. Повторяем до обработки всех точек.

	### **Преимущества DBSCAN**
	- **Не требует заранее задавать число кластеров.**
	- **Выявляет кластеры произвольной формы**, не только круглые, как K-Means.
	- **Устойчив к шуму** — точки вне плотных областей автоматически выделяются как шум.
	- **Хорош для данных с различной плотностью** (с некоторыми ограничениями, можно комбинировать с HDBSCAN).

14. Допы

	### **bias-variance-decomposition**

	Bootstrap-выборка - случайная выборка объектов из $\Omega$ 
	$D = \{ \Omega \}$
	Условимся, что ошибка у нас гомоскидастична ($\mathbb E_{D}[\varepsilon] = 0, E_{D}[\varepsilon^{2}] = \sigma^{2}$)
		$$\mathbb E_{D} [(f(x) + \varepsilon - \hat{ f}(x))^{2}] = \mathbb E_{D}[((f(x) - \hat{f}(x)) - \varepsilon)^{2}] = $$
		$$=\mathbb E_{D} [(f(x) - \hat{f}(x))^{2}] + 2\mathbb E_{D}[(f(x) - \hat{f}(x)) \varepsilon] (=0) + \mathbb E_{D}[\varepsilon^{2}]$$
		Добавим и вычтем  в первое слагаемое матожидание нашей оценки:
		$$
		=\mathbb E_{D} [(f(x) - \mathbb E_{D}[\hat{f}(x)] + \mathbb E_{D}[\hat{f}(x)] -\hat{f}(x))^{2}] + \sigma^{2}=
		$$
		Раскрыв скобки и сократив лишнее, получим:
		$$= \underbrace{(f(x) - \mathbb E_{D}[\hat{f}(x)])^{2}}_{\text{bias}^{2}} + \mathbb E_{D}[(\hat{f}(x) - \underbrace{\mathbb E_{D}[\hat{f}(x)])^{2}]}_{\text{variance}} + \underbrace{\sigma^{2}}_{Var(\varepsilon)}$$

	### **Bagging**
	- это ансамблевый метод, где несколько моделей (обычно одного типа, например, деревья решений) обучаются на разных случайных подвыборках данных (с возвращением), а их предсказания агрегируются (усреднение для регрессии, голосование для классификации).
	- Снижает дисперсию (борется с переобучением).
	- Каждая модель видит слегка разные данные, ошибки усредняются.
	- Пример алгоритма: **Random Forest** — это по сути bagging деревьев с дополнительной случайной выборкой признаков.

	### **stacking**
	- объединяет несколько моделей (можно разных типов), обучая **мета-модель**, которая учится комбинировать их предсказания.
	- Базовые модели обучаются на тренировочных данных.
	- Их предсказания становятся признаками для мета-модели (например, логистическая регрессия).
	- Снижает смещение и дисперсию при разнообразии базовых моделей.
	- Базовые модели: Random Forest, XGBoost, SVM.
	- Мета-модель: логистическая регрессия.
	- Обучаем базовые модели → получаем предсказания на валидации → обучаем мета-модель на этих предсказаниях → финальное предсказание.

	### **cross-val (k-fold)**
	**Суть:**  
	k-fold CV делит данные на k равных частей («folds»). Каждая часть используется один раз как валидация, а остальные k-1 части — для обучения.

	**Детали:**
	- Дает более надежную оценку качества модели.
	- Обычно k = 5 или 10.
	- Снижает зависимость от одной случайной разбивки на train/test.

	### **out of time**
	Используется для временных рядов или данных с временной зависимостью. Модель тестируется на **поздней временной выборке**, чем тренировочная.
	- Имитирует реальное использование модели на будущем.
	- Исключает утечку будущей информации.

	### **out of sample**
	Тестирование модели на **полностью новых данных**, которые не использовались в обучении и подборе гиперпараметров.
	- Проверяет обобщающую способность модели.
	- Это может быть отдельная тестовая выборка или данные с другого источника.